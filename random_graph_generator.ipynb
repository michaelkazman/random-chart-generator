{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Contains import statements for all the required libraries and frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "from utils.utils import get_library_class\n",
    "from utils.generators import generate_data\n",
    "from utils.styles import generate_styles\n",
    "from utils.creators import create_graph\n",
    "from utils.exporters import (\n",
    "    export_graph_data,\n",
    "    export_graph_styles,\n",
    "    export_graph_image,\n",
    "    convert_from_serializable,\n",
    "    LOG_LEVEL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Hyperparameters\n",
    "Specifies the maximum number of graphs to be generated\n",
    "\n",
    "Additionally, the types of libraries and plots can be specified as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of graphs to be generated\n",
    "max_num_graphs = 30000\n",
    "\n",
    "# list of all potential graph types\n",
    "graph_types = [\n",
    "    'area',\n",
    "    'bar',\n",
    "    'box',\n",
    "    'bubble',\n",
    "    'contour',\n",
    "    'errorbar',\n",
    "    'histogram',\n",
    "    'kde',\n",
    "    'line',\n",
    "    'scatter',\n",
    "    'violin',\n",
    "]\n",
    "\n",
    "# set of libraries generating graphs\n",
    "libraries = [\n",
    "    'bokeh',\n",
    "    'altair',\n",
    "    'plotnine',\n",
    "]\n",
    "\n",
    "# exclude certain graph-library combinations\n",
    "exclusions = [\n",
    "    ('contour', 'altair'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Set up and clean the pipeline environment\n",
    "\n",
    "Tasks such as cleaning the output folders and setting up a logger are done here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories\n",
    "OUTPUT_DIR = 'output'\n",
    "INGESTION_DIR = 'ingestion'\n",
    "LOG_DIR = 'logs'\n",
    "\n",
    "# empty output folder\n",
    "for folder in ['data', 'styles', 'images']:\n",
    "    path = '{dir}/{folder}'.format(dir=OUTPUT_DIR, folder=folder)\n",
    "    for file in os.listdir(path):\n",
    "        if file != '__init__.py':\n",
    "            os.remove(os.path.join(path, file))\n",
    "\n",
    "# setup logger\n",
    "timestamp = datetime.now().strftime('%d_%m_%Y-%I_%M_%S')\n",
    "logging.basicConfig(\n",
    "    filename='{dir}/{timestamp}.log'.format(dir=LOG_DIR, timestamp=timestamp),\n",
    "    encoding='utf-8',\n",
    "    level=LOG_LEVEL,\n",
    "    format='%(asctime)s %(message)s',\n",
    "    datefmt='%m/%d/%Y %I:%M:%S',\n",
    "    force=True,\n",
    ")\n",
    "\n",
    "# setup libraries (where applicable)\n",
    "for library in libraries:\n",
    "    library_class = get_library_class(library)\n",
    "    library_class.setup_hook()\n",
    "\n",
    "# generate dict for each possible graph type\n",
    "# (e.g. { 'scatter': {}, 'bar': {}, ... })\n",
    "graphs = dict(\n",
    "    zip(graph_types, [{} for _ in range(len(graph_types))])\n",
    ")\n",
    "pprint(graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Separation\n",
    "Generates a dict representing the number of graphs that need to be created for each library/graph pair\n",
    "\n",
    "The dictionary keys represent `(library, graph)` where the value represents the number of graphs to be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_occurences_dict(\n",
    "    num_graphs,\n",
    "    graph_types,\n",
    "    libraries,\n",
    "    equal_library_distribution=True,\n",
    "    equal_graph_distribution=True,\n",
    "):\n",
    "    # dict for storing the number of graphs per library / graph to generate\n",
    "    # (e.g. occurences['bokeh', 'bar'] might return a value of 5)\n",
    "    occurences, library_occurences, graph_occurences = {}, [], [] \n",
    "    \n",
    "    # split graph occurences (1-d array)\n",
    "    split_graph_func =  split_number_evenly if equal_graph_distribution else split_number_randomly\n",
    "    graph_occurences = split_graph_func(num_graphs, len(graph_types))\n",
    "\n",
    "    # split library occurences (2-d array)\n",
    "    split_library_func = split_number_evenly if (equal_library_distribution) else split_number_randomly\n",
    "    for graph_index, num_graphs_per_type in enumerate(graph_occurences):\n",
    "        # only distribute graph occurences to available libraries (i.e. ones that aren't excluded)\n",
    "        graph_exclusions = list(filter(lambda x: x[0] == graph_types[graph_index] and x[1] in libraries, exclusions))\n",
    "        library_occurence = split_library_func(num_graphs_per_type, len(libraries) - len(graph_exclusions))\n",
    "        # splice an occurence of 0 at all the unavaiable library positions\n",
    "        # filter is needed to avoid indexing elements that don't exist\n",
    "        library_indices = sorted(map(lambda x: libraries.index(x[1]), filter(lambda x: x[1] in libraries, graph_exclusions)))\n",
    "        _ = [library_occurence.insert(library_index, 0) for library_index in library_indices]\n",
    "        library_occurences.append(library_occurence)\n",
    "\n",
    "    # add values generated above to occurence dict\n",
    "    for i, num_graphs_per_type in enumerate(library_occurences):\n",
    "        for j, num_graphs_per_library in enumerate(num_graphs_per_type):\n",
    "            graph_type, library = graph_types[i], libraries[j]\n",
    "            occurences[graph_type, library] = num_graphs_per_library\n",
    "    return occurences\n",
    "\n",
    "def split_number_evenly(n, n_arrays):\n",
    "    values = np.linspace(n, 0, n_arrays+1).astype(int)\n",
    "    return [value - values[i+1] for i, value in enumerate(values[:-1])]\n",
    "\n",
    "def split_number_randomly(n, n_arrays):\n",
    "    number, numbers = n, []\n",
    "    while (number > 0):\n",
    "        random_number = number if len(numbers) == n_arrays - 1 else round(random.random()*number)\n",
    "        numbers.append(random_number)\n",
    "        number -= random_number\n",
    "    numbers.extend([0] * (n_arrays - len(numbers)))\n",
    "    return random.sample(numbers, len(numbers))\n",
    "\n",
    "# generate graph occurence dictionary\n",
    "graph_types = list(graphs.keys())\n",
    "occurences = generate_occurences_dict(max_num_graphs, graph_types, libraries)\n",
    "pprint(occurences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "Generates the corresponding data based on graph type (i.e. `generate_bar()`)\n",
    "\n",
    "Data is stored in a generated_graphs object (i.e. an `X` attribute in said graph object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevents inline chart display\n",
    "%matplotlib agg\n",
    "\n",
    "# append objects in the format { id, library, data, etc. } to each corresponding graph type\n",
    "# e.g. graphs['bar']['graphs'] might equal [{ id: 1, library: 'bokeh', data: [[1, 2, 3]]}, ...]\n",
    "generated_graphs = deepcopy(graphs)\n",
    "graph_type_id, current_graph_type = 0, None\n",
    "for (graph_type, library), num_occurences in occurences.items():\n",
    "    # use a counter to track how many entries belong to the current graph type\n",
    "    if (current_graph_type != graph_type):\n",
    "        graph_type_id = 0\n",
    "        current_graph_type = graph_type\n",
    "\n",
    "    # generate a n-length set of data points,\n",
    "    # where n is something like occurences['bar', 'bokeh']\n",
    "    graphs_list = generated_graphs[graph_type].setdefault('graphs', [])\n",
    "    for _ in range(num_occurences):\n",
    "        data = generate_data(graph_type)\n",
    "        graphs_list.append({\n",
    "            'id': graph_type_id,\n",
    "            'library': library,\n",
    "            'data': data,\n",
    "        })\n",
    "        graph_type_id += 1\n",
    "\n",
    "# resets inline chart display back to original settings\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Stylization\n",
    "Generates styles for a given library-graph pair (e.g. `generate_style(library, graph)`)\n",
    "\n",
    "Calls the `generate_bokeh_styles`, `generate_altair_styles`, and `generate_plotnine_styles` functions for each style module dynamically\n",
    "\n",
    "The stylization code for each graph can be found in the `styles` dir respectively (i.e. `styles/bar.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through each graph and generated corresponding style and theming objects\n",
    "for (graph_type, graph_object) in generated_graphs.items():\n",
    "    for graph_content in graph_object['graphs']:\n",
    "        library, num_repeats = graph_content['library'], graph_content['data'].get('num_repeats', 1)\n",
    "        graph_content['styles'] = generate_styles(graph_type, library, num_repeats)\n",
    "        graph_content['data'].pop('num_repeats', None)\n",
    "\n",
    "# displays generated styles objects\n",
    "pprint([[graph_content['styles'] for graph_content in graph_object['graphs']] for graph_object in generated_graphs.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Creation\n",
    "Uses the generated data points and styles to create the respective graphs\n",
    "\n",
    "Additional flags can be used to specify the output file path and file type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (graph_type, graph_object) in generated_graphs.items():\n",
    "    for graph_content in graph_object['graphs']:\n",
    "        # retrieves the create_LIBRARY_graph function based on the graphs\n",
    "        # library and then appends the created graph to the same object\n",
    "        library = graph_content['library']\n",
    "        graph = create_graph(graph_type, library, graph_content)\n",
    "        \n",
    "        # export content to filepath\n",
    "        id = graph_content['id']\n",
    "        file_name = '{graph_type}_{library}_{id}'.format(graph_type=graph_type, library=library, id=id)\n",
    "\n",
    "        # save data, styles, and images to disk\n",
    "        export_graph_data(graph_content['data'], 'output/{path}/{file_name}.{file_type}'\n",
    "            .format(file_name=file_name, path='data', file_type='json'))\n",
    "        export_graph_styles(graph_content['styles'], 'output/{path}/{file_name}.{file_type}'\n",
    "            .format(file_name=file_name, path='styles', file_type='json'))\n",
    "        export_graph_image(graph, library, 'output/{path}/{file_name}.{file_type}'\n",
    "            .format(file_name=file_name, path='images', file_type='png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Regeneration\n",
    "The ability to regenerate graphs is critical, as the pipeline above will be involved in creating input data for a Generative Adversarial Network. It is neccessary to compare the images from both the original pipeline as well as the GAN in order to assess the network's accuracy\n",
    "\n",
    "By supplying input data to the `input/data` and `input/styles` folders, the following cell will read in the data, generate the corresponding charts, and export the data to the `input/images` folder\n",
    "\n",
    "The inputted data and styles files are required to be in `json` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevents inline chart display\n",
    "%matplotlib agg\n",
    "\n",
    "# retrieve a list of contents from the specified input folders\n",
    "input_folders = ['data', 'styles']\n",
    "input_folder_paths = ['{dir}/{folder}'.format(dir=INGESTION_DIR, folder=folder) for folder in input_folders]\n",
    "input_folder_contents = [set(os.listdir(path)) for path in input_folder_paths]\n",
    "\n",
    "# only keep filenames of the graphs with all required files\n",
    "valid_input_graphs = set.intersection(*input_folder_contents)\n",
    "_ = [valid_input_graphs.discard(file) for file in ['__init__.py', '__pycache__']]\n",
    "\n",
    "# setup libraries (where applicable)\n",
    "for library in libraries:\n",
    "    library_class = get_library_class(library)\n",
    "    library_class.setup_hook()\n",
    "\n",
    "# retrieve graph type and library based on filename\n",
    "graphs = [graph.split('_', maxsplit=3) for graph in valid_input_graphs]\n",
    "for graph_filepath in valid_input_graphs:\n",
    "  # extract graph data (from filename) and re-generate the expected data structure\n",
    "  # uses the given filename to retrieve the input files on disk\n",
    "  graph_filename = graph_filepath.split('.', maxsplit=1)[0]\n",
    "  graph_type, library, id = graph_filename.split('_', maxsplit=3)\n",
    "  graph_content = {}\n",
    "  # note that the object property will be equal to the input folder name\n",
    "  # i.e. files in input/data will be stored as object['data']\n",
    "  for folder in input_folders:\n",
    "    with open('{dir}/{folder}/{file_name}'.format(dir=INGESTION_DIR, folder=folder, file_name=graph_filepath)) as f:\n",
    "      graph_content[folder] = convert_from_serializable(json.load(f))\n",
    "  # create and export graph\n",
    "  graph = create_graph(graph_type, library, graph_content)\n",
    "  export_graph_image(graph, library, '{dir}/{path}/{file_name}.{file_type}'\n",
    "    .format(dir=INGESTION_DIR, file_name=graph_filename, path='images', file_type='png'))\n",
    "\n",
    "logging.shutdown()\n",
    "\n",
    "# resets inline chart display back to original settings\n",
    "%matplotlib inline"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4ffe1cccd6b8935c088250f646007b8f4ca77d2f7799c1e6d17e1b6461115b4"
  },
  "kernelspec": {
   "display_name": "Random Graph Generator Kernel (Python 3.9.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
